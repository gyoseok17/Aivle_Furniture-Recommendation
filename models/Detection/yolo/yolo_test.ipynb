{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13547,"status":"ok","timestamp":1703645213038,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"rzWvXTeX552T","outputId":"6a3690db-018d-4f08-b521-d7899e8c4833"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/69.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/158.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install roboflow -q"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8320,"status":"ok","timestamp":1703645434071,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"o9A1fl2tgBIl","outputId":"c1cf746c-7569-4267-a76c-fb8e0365ad00"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/663.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/663.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m655.4/663.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.2/663.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install ultralytics -q"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19095,"status":"ok","timestamp":1703645199494,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"k2hBm_M9fX1b","outputId":"6e2a0d1e-3a15-4a79-ede0-785139645644"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"XA0-Z3mX6MBD"},"source":["## 로보 플로우 데이터셋"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16790,"status":"ok","timestamp":1703645233070,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"WMud3FqZeXyR","outputId":"58521b56-63cd-4881-e15b-7c4db8dcc20e"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.196`, to intall it `pip install ultralytics==8.0.196`.\n"]},{"name":"stderr","output_type":"stream","text":["Downloading Dataset Version Zip in furniture-detection-20 to yolov8:: 100%|██████████| 176357/176357 [00:09<00:00, 19381.40it/s]"]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["\n","Extracting Dataset Version Zip to furniture-detection-20 in yolov8:: 100%|██████████| 16125/16125 [00:03<00:00, 4590.38it/s]\n"]}],"source":["from roboflow import Roboflow\n","\n","rf = Roboflow(api_key=\"TBDNbDNNjBRxOoBGiu48\")\n","project = rf.workspace(\"mokhamed-nagy-u69zl\").project(\"furniture-detection-qiufc\")\n","dataset = project.version(20).download(\"yolov8\")\n"]},{"cell_type":"markdown","metadata":{"id":"ujHPvgOO6OXU"},"source":["## 파일 관련 (이동, 갯수 계산, 사이즈 변환)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OV70SyTQdHF"},"outputs":[],"source":["#전체 폴더 이동\n","import os\n","import shutil\n","\n","source_folder = '/content/furniture-detection-20'  # 이동시킬 원본 폴더\n","destination_folder = '/content/drive/MyDrive/Colab Notebooks/BigP/dataset'  # 파일을 이동할 대상 폴더\n","\n","# 대상 폴더가 없으면 생성\n","if not os.path.exists(destination_folder):\n","    os.makedirs(destination_folder)\n","\n","# 원본 폴더의 모든 내용(파일 및 하위 폴더)을 대상 폴더로 이동\n","for item in os.listdir(source_folder):\n","    source_path = os.path.join(source_folder, item)\n","    destination_path = os.path.join(destination_folder, item)\n","\n","    # 이동\n","    shutil.move(source_path, destination_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-PfRlFXSJyqB"},"outputs":[],"source":["#파일 이동\n","import os\n","import shutil\n","\n","source_folder = '/content/runs/detect/train/weights'\n","destination_folder = '/content/drive/MyDrive/Colab Notebooks/BigP/weights/x_e100'\n","\n","# 대상 폴더가 없으면 생성\n","if not os.path.exists(destination_folder):\n","    os.makedirs(destination_folder)\n","\n","for filename in os.listdir(source_folder):\n","    source_path = os.path.join(source_folder, filename)\n","    destination_path = os.path.join(destination_folder, filename)\n","    # 파일 이동\n","    shutil.move(source_path, destination_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":527,"status":"ok","timestamp":1703057919970,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"QE78ZnlvF9F6","outputId":"5a335220-eb51-46aa-de7f-9027012e7cb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["images 파일 수: 891\n","labels 파일 수: 891\n"]}],"source":["#파일 수 계산\n","import os\n","def count_files(directory):\n","    return sum([len(files) for r, d, files in os.walk(directory)])\n","\n","aa = '/content/drive/MyDrive/Colab Notebooks/BigP/dataset/valid'  # 폴더 경로 지정\n","folder_path = f'{aa}/images'  # 폴더 경로 지정\n","folder_path2 = f'{aa}/labels'  # 폴더 경로 지정\n","print(f\"images 파일 수: {count_files(folder_path)}\")\n","print(f\"labels 파일 수: {count_files(folder_path2)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IX71LOpA6ejJ"},"outputs":[],"source":["# 이미지 크기 조절\n","from ultralytics import YOLO\n","from PIL import Image\n","import os, torch\n","\n","folder_path = '/content/'\n","for filename in os.listdir(folder_path):\n","    if filename.endswith('.png'):\n","        img_path = os.path.join(folder_path, filename)\n","        with Image.open(img_path) as img:\n","            # 이미지 크기 조절\n","            img_resized = img.resize((640, 640))\n","\n","            # 변경된 이미지 저장\n","            img_resized.save(img_path)"]},{"cell_type":"markdown","metadata":{"id":"oZ2qPY92vaC6"},"source":["## YOLOv7"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3819,"status":"ok","timestamp":1703645236887,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"RGSgnVV1vdNd","outputId":"f0fafba3-e782-4aa0-f915-a6c7dd223ab8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 1197, done.\u001b[K\n","remote: Total 1197 (delta 0), reused 0 (delta 0), pack-reused 1197\u001b[K\n","Receiving objects: 100% (1197/1197), 74.23 MiB | 29.70 MiB/s, done.\n","Resolving deltas: 100% (520/520), done.\n","/content/yolov7\n"]}],"source":["!git clone https://github.com/WongKinYiu/yolov7.git\n","%cd yolov7"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1703645245430,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"8CrnHdM4v9w6","outputId":"20006840-66a5-453f-9131-5ae11ec27cf4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Installing collected packages: jedi, thop\n","Successfully installed jedi-0.19.1 thop-0.1.1.post2209072238\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AWj2a-lfwAOq"},"outputs":[],"source":["!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4TskPdh3wAB4"},"outputs":[],"source":["# 코코 아마도?\n","!python detect.py --weights yolov7-e6e.pt --conf 0.25 --source '/content/testimg' --save-txt --save-conf --project '/content/pred' --name 'hi'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ak4PY2nTG71R"},"outputs":[],"source":["!python train_aux.py --workers 8 --device 0 --batch-size 16 --data /content/furniture-detection-20/data.yaml --img 1280 1280 --cfg cfg/training/yolov7-w6.yaml --weights '' --name yolov7-w6 --hyp data/hyp.scratch.p6.yaml\n"]},{"cell_type":"markdown","metadata":{"id":"6-gYk7CL6V3b"},"source":["## YOLOv8"]},{"cell_type":"markdown","metadata":{"id":"NlzpopVELe7h"},"source":["### large Model"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1871,"status":"ok","timestamp":1703650440901,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"Gzif-GdyeXyT","outputId":"eb122271-35e7-4d88-a0c9-b5d1f1c03eaf"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3822016  ultralytics.nn.modules.head.Detect           [80, [192, 384, 576]]         \n","YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPs\n","\n","Transferred 469/475 items from pretrained weights\n"]}],"source":["#라지 모델 불러오기\n","from ultralytics import YOLO\n","model_m = YOLO('yolov8m.yaml').load('/content/yolov7/runs/detect/train/weights/best.pt')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3522080,"status":"ok","timestamp":1703653973266,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"3QtBOvvFeXyT","outputId":"7b6d29a8-4a05-4a4e-a527-cbce7272d28f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.0.230 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.yaml, data=/content/furniture-detection-20/data.yaml, epochs=30, time=None, patience=50, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n","Overriding model.yaml nc=80 with nc=25\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3790171  ultralytics.nn.modules.head.Detect           [25, [192, 384, 576]]         \n","YOLOv8m summary: 295 layers, 25870795 parameters, 25870779 gradients, 79.1 GFLOPs\n","\n","Transferred 469/475 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/furniture-detection-20/train/labels.cache... 6424 images, 369 backgrounds, 0 corrupt: 100%|██████████| 6424/6424 [00:00<?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3293, len(boxes) = 8564. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/furniture-detection-20/valid/labels.cache... 891 images, 66 backgrounds, 0 corrupt: 100%|██████████| 891/891 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 226, len(boxes) = 1023. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to runs/detect/train2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000345, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       1/30      3.37G     0.9569       2.16      1.599         33        416: 100%|██████████| 402/402 [01:49<00:00,  3.68it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:09<00:00,  3.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.432      0.367       0.36      0.227\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       2/30      3.27G     0.9733      1.994      1.604         30        416: 100%|██████████| 402/402 [01:43<00:00,  3.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:07<00:00,  3.59it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.551      0.314       0.36      0.209\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       3/30      3.25G     0.9885      1.977       1.61         27        416: 100%|██████████| 402/402 [01:47<00:00,  3.74it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.35it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.438      0.395      0.316       0.17\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       4/30      3.27G     0.9878      1.934      1.608         24        416: 100%|██████████| 402/402 [01:43<00:00,  3.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:09<00:00,  2.97it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.552      0.287      0.323      0.205\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       5/30      3.25G     0.9849      1.934      1.603         23        416: 100%|██████████| 402/402 [01:43<00:00,  3.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.30it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.435       0.44       0.36      0.213\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       6/30      3.27G     0.9735      1.876      1.598         22        416: 100%|██████████| 402/402 [01:49<00:00,  3.69it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:09<00:00,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.306      0.344      0.315      0.186\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       7/30      3.25G     0.9683      1.827      1.583         23        416: 100%|██████████| 402/402 [01:47<00:00,  3.73it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.18it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.444      0.355      0.328      0.209\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       8/30      3.27G      0.957      1.806      1.576         28        416: 100%|██████████| 402/402 [01:48<00:00,  3.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:08<00:00,  3.32it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023       0.41      0.384      0.377      0.231\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       9/30      3.27G      0.938      1.776      1.565         30        416: 100%|██████████| 402/402 [01:52<00:00,  3.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:07<00:00,  3.61it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.428       0.31      0.326      0.198\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      10/30      3.27G     0.9326       1.75      1.555         29        416: 100%|██████████| 402/402 [01:47<00:00,  3.73it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:08<00:00,  3.33it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.454      0.447      0.412      0.249\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      11/30      3.26G     0.9194      1.724      1.548         20        416: 100%|██████████| 402/402 [01:48<00:00,  3.69it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.29it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.466      0.447      0.418      0.249\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      12/30      3.25G     0.9191      1.699      1.547         28        416: 100%|██████████| 402/402 [01:48<00:00,  3.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.33it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.458      0.421      0.415      0.255\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      13/30      3.25G     0.9028      1.662      1.535         21        416: 100%|██████████| 402/402 [01:43<00:00,  3.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:09<00:00,  3.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.578      0.356      0.417      0.247\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      14/30      3.27G     0.8945       1.63       1.53         19        416: 100%|██████████| 402/402 [01:43<00:00,  3.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.33it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.481      0.424      0.424      0.264\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      15/30      3.27G     0.8837      1.618      1.518         21        416: 100%|██████████| 402/402 [01:48<00:00,  3.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.26it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023       0.54      0.406      0.434      0.265\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      16/30      3.25G     0.8739      1.578      1.503         21        416: 100%|██████████| 402/402 [01:42<00:00,  3.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:08<00:00,  3.12it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.499      0.431      0.444      0.273\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      17/30      3.26G     0.8661      1.554      1.507         28        416: 100%|██████████| 402/402 [01:43<00:00,  3.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:08<00:00,  3.18it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.416      0.458      0.426       0.27\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      18/30      3.26G     0.8706      1.553      1.503         21        416: 100%|██████████| 402/402 [01:43<00:00,  3.89it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.44it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023       0.47      0.418      0.433      0.274\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      19/30      3.25G     0.8543      1.519      1.492         30        416: 100%|██████████| 402/402 [01:43<00:00,  3.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:08<00:00,  3.39it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.458      0.457      0.438      0.269\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      20/30      3.27G     0.8308      1.472      1.473         25        416: 100%|██████████| 402/402 [01:43<00:00,  3.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.29it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.462      0.433      0.435      0.276\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      21/30      3.26G     0.8075      1.281      1.498          9        416: 100%|██████████| 402/402 [01:40<00:00,  4.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:08<00:00,  3.27it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.448      0.455      0.458      0.294\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      22/30      3.27G     0.7873      1.208      1.478          8        416: 100%|██████████| 402/402 [01:37<00:00,  4.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.26it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.484      0.448      0.476      0.298\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      23/30      3.25G     0.7621      1.174      1.458         10        416: 100%|██████████| 402/402 [01:36<00:00,  4.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.24it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.541      0.473      0.492      0.317\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      24/30      3.27G     0.7508      1.126      1.446         12        416: 100%|██████████| 402/402 [01:32<00:00,  4.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:07<00:00,  3.64it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023        0.6      0.477      0.527      0.333\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      25/30      3.24G     0.7397      1.101      1.434          8        416: 100%|██████████| 402/402 [01:36<00:00,  4.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.37it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.553      0.486      0.509      0.319\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      26/30      3.26G     0.7172      1.056      1.416         12        416: 100%|██████████| 402/402 [01:32<00:00,  4.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:08<00:00,  3.24it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.563      0.493      0.521      0.343\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      27/30      3.24G     0.7064      1.026      1.406          9        416: 100%|██████████| 402/402 [01:38<00:00,  4.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.35it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.587      0.488      0.535      0.338\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      28/30      3.26G     0.6986     0.9993        1.4          8        416: 100%|██████████| 402/402 [01:35<00:00,  4.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:07<00:00,  3.85it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.483      0.531      0.519      0.345\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      29/30      3.26G     0.6834     0.9821      1.384         11        416: 100%|██████████| 402/402 [01:35<00:00,  4.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:07<00:00,  3.85it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.538      0.495      0.527       0.34\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      30/30      3.26G     0.6735     0.9685      1.378          9        416: 100%|██████████| 402/402 [01:34<00:00,  4.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.40it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.562       0.49      0.531      0.342\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","30 epochs completed in 0.965 hours.\n","Optimizer stripped from runs/detect/train2/weights/last.pt, 52.0MB\n","Optimizer stripped from runs/detect/train2/weights/best.pt, 52.0MB\n","\n","Validating runs/detect/train2/weights/best.pt...\n","Ultralytics YOLOv8.0.230 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","YOLOv8m summary (fused): 218 layers, 25854235 parameters, 0 gradients, 78.8 GFLOPs\n"]},{"name":"stderr","output_type":"stream","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:11<00:00,  2.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.482      0.532      0.519      0.345\n","                   Bed        891         71      0.729      0.873      0.832      0.619\n","               Cabinet        891         55      0.535      0.545      0.567      0.398\n","                Carpet        891         18      0.275        0.5      0.459      0.341\n","         Ceramic floor        891         12      0.216      0.482      0.146      0.103\n","                 Chair        891         76      0.681      0.562      0.642      0.424\n","                Closet        891         31      0.492      0.581      0.582      0.452\n","              Cupboard        891         25      0.489      0.727      0.729      0.556\n","              Curtains        891         23      0.264      0.304      0.291      0.206\n","          Dining Table        891         39      0.729      0.282      0.503      0.304\n","                  Door        891          9      0.159      0.111      0.162      0.122\n","                 Frame        891          3     0.0541      0.198      0.117     0.0617\n","           Futec frame        891          7      0.185      0.429      0.303     0.0936\n","          Futech tiles        891          3      0.734      0.667       0.83      0.422\n","          Gypsum Board        891         10      0.695      0.684      0.637      0.522\n","                  Lamp        891         32      0.562      0.625      0.587      0.284\n","            Nightstand        891         13      0.434      0.591      0.559      0.395\n","                 Shelf        891         38      0.883      0.595      0.799       0.57\n","             Sideboard        891         16      0.288      0.438      0.312      0.185\n","                  Sofa        891        238      0.916      0.899       0.95      0.709\n","              TV stand        891         34      0.609      0.647      0.647      0.372\n","                 Table        891        109      0.843      0.638      0.737      0.526\n","    Transparent Closet        891          5      0.433        0.8      0.806      0.477\n","            Wall Panel        891         11      0.232      0.455      0.258      0.165\n","                Window        891        126      0.545      0.413      0.462      0.277\n","          Wooden floor        891         19     0.0784      0.263     0.0624     0.0372\n","Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 2.2ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"]}],"source":["#라지 모델 학습 / patience - 몇번까지 성능향상 없으면 조기중단\n","results_m = model_m.train(data='/content/furniture-detection-20/data.yaml', epochs=30, imgsz=416)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7367,"status":"ok","timestamp":1703056988561,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"TcVSLzDNE41p","outputId":"a2875c32-993f-448f-834b-a3851c4a2aba"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","image 1/1 /content/11.png: 640x640 (no detections), 2174.0ms\n","Speed: 2.3ms preprocess, 2174.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","\n","image 1/1 /content/22.png: 640x640 (no detections), 2618.1ms\n","Speed: 1.8ms preprocess, 2618.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","\n","image 1/1 /content/33.png: 640x640 (no detections), 2094.7ms\n","Speed: 1.7ms preprocess, 2094.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"]}],"source":["fn = ['11','22','33']\n","for n in fn:\n","    model_l.predict(f\"/content/{n}.png\", save=True, imgsz=640, conf=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIiR5WpSW3C9"},"outputs":[],"source":["#predict: conf 조절\n","fn = ['11','22','44','55']\n","for n in fn:\n","    model_l.predict(f\"/content/Timg/{n}.jpg\", save=True, imgsz=640, conf=0.1)"]},{"cell_type":"markdown","metadata":{"id":"6_T1FgSVLsnx"},"source":["### extreme"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2429,"status":"ok","timestamp":1703121930481,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"OIvMWXtTLmxF","outputId":"e0f62b70-58be-4294-d34f-ad6013ad3374"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n","  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n","  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n","  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n","  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n","  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n","  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n","  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n","  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n","  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n"," 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n"," 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 22        [15, 18, 21]  1   8795008  ultralytics.nn.modules.head.Detect           [80, [320, 640, 640]]         \n","YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs\n","\n","Transferred 589/595 items from pretrained weights\n"]}],"source":["#익스트림 모델 불러오기\n","from ultralytics import YOLO\n","model_x = YOLO('yolov8x.yaml').load('/content/drive/MyDrive/Colab Notebooks/BigP/weights/x_e100/best.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3523068,"status":"ok","timestamp":1703121588135,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"pJ1BRh--eXyU","outputId":"2f46cf51-5f72-49c5-ee27-c8d048fccdfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.0.228 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.yaml, data=/content/drive/MyDrive/Colab Notebooks/BigP/dataset/data.yaml, epochs=50, time=None, patience=10, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=None, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 755k/755k [00:00<00:00, 37.4MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Overriding model.yaml nc=80 with nc=25\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n","  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n","  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n","  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n","  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n","  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n","  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n","  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n","  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n","  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n"," 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n"," 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 22        [15, 18, 21]  1   8742043  ultralytics.nn.modules.head.Detect           [25, [320, 640, 640]]         \n","YOLOv8x summary: 365 layers, 68176683 parameters, 68176667 gradients, 258.3 GFLOPs\n","\n","Transferred 589/595 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6.23M/6.23M [00:00<00:00, 196MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["WARNING ⚠️ NMS time limit 0.550s exceeded\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/BigP/dataset/train/labels.cache... 7163 images, 419 backgrounds, 0 corrupt: 100%|██████████| 7163/7163 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3490, len(boxes) = 9410. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Colab Notebooks/BigP/dataset/valid/labels.cache... 891 images, 66 backgrounds, 0 corrupt: 100%|██████████| 891/891 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 226, len(boxes) = 1023. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000345, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n","50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       1/50      6.33G     0.4868     0.7746      1.072         35        416: 100%|██████████| 448/448 [29:24<00:00,  3.94s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:12<00:00,  2.21it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.639      0.563      0.609      0.452\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       2/50      6.62G     0.5957     0.8257      1.129         27        416: 100%|██████████| 448/448 [02:20<00:00,  3.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:12<00:00,  2.30it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023       0.64      0.517      0.577      0.438\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       3/50      6.33G     0.6352     0.8769      1.154         23        416: 100%|██████████| 448/448 [02:18<00:00,  3.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:10<00:00,  2.58it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.588      0.548      0.571      0.426\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       4/50      6.62G     0.6407     0.9009      1.156         40        416: 100%|██████████| 448/448 [02:20<00:00,  3.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:09<00:00,  3.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.558      0.604      0.576      0.423\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       5/50       6.6G     0.6493     0.8932       1.16         35        416: 100%|██████████| 448/448 [02:22<00:00,  3.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:09<00:00,  2.91it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.601      0.564      0.564      0.417\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       6/50      6.61G     0.6384     0.8808      1.159         31        416: 100%|██████████| 448/448 [02:19<00:00,  3.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:09<00:00,  2.88it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023       0.56      0.562      0.551       0.39\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       7/50      6.61G     0.6323     0.8581      1.149         45        416: 100%|██████████| 448/448 [02:19<00:00,  3.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:11<00:00,  2.53it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.605      0.517      0.559      0.405\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       8/50       6.6G     0.6234     0.8538      1.149         28        416: 100%|██████████| 448/448 [02:19<00:00,  3.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:09<00:00,  2.82it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.562      0.537      0.545      0.414\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       9/50      6.62G     0.6211     0.8301      1.143         39        416: 100%|██████████| 448/448 [02:22<00:00,  3.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:09<00:00,  2.99it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.634      0.522       0.56      0.429\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      10/50      6.61G     0.6186     0.8139      1.144         44        416: 100%|██████████| 448/448 [02:17<00:00,  3.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:11<00:00,  2.48it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.576      0.558      0.538      0.408\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      11/50       6.6G      0.602     0.7875      1.134         38        416: 100%|██████████| 448/448 [02:23<00:00,  3.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:11<00:00,  2.51it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.633      0.559      0.591      0.439\n","Stopping training early as no improvement observed in last 10 epochs. Best results observed at epoch 1, best model saved as best.pt.\n","To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","11 epochs completed in 0.939 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 136.7MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 136.7MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics YOLOv8.0.228 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","YOLOv8x summary (fused): 268 layers, 68147643 parameters, 0 gradients, 257.5 GFLOPs\n"]},{"name":"stderr","output_type":"stream","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:13<00:00,  2.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        891       1023      0.637      0.562      0.609      0.451\n","                   Bed        891         71      0.887      0.773      0.842      0.687\n","               Cabinet        891         55      0.811      0.545      0.652      0.557\n","                Carpet        891         18      0.237      0.444      0.448      0.421\n","         Ceramic floor        891         12      0.502      0.417      0.408      0.282\n","                 Chair        891         76      0.786      0.724      0.831      0.622\n","                Closet        891         31      0.961      0.796      0.951      0.843\n","              Cupboard        891         25      0.788      0.744      0.833      0.744\n","              Curtains        891         23       0.38      0.391      0.355      0.277\n","          Dining Table        891         39      0.759       0.59       0.63      0.416\n","                  Door        891          9      0.648      0.209      0.332      0.203\n","                 Frame        891          3          0          0     0.0468     0.0411\n","           Futec frame        891          7      0.306      0.286      0.204      0.105\n","          Futech tiles        891          3      0.461      0.667       0.83      0.202\n","          Gypsum Board        891         10      0.599        0.5      0.596      0.472\n","                  Lamp        891         32      0.851      0.712      0.694      0.496\n","            Nightstand        891         13      0.379      0.769       0.56      0.413\n","                 Shelf        891         38      0.971      0.868      0.954      0.675\n","             Sideboard        891         16      0.698        0.5      0.567      0.495\n","                  Sofa        891        238      0.973      0.945       0.98      0.773\n","              TV stand        891         34      0.709      0.794      0.768      0.571\n","                 Table        891        109      0.902      0.758      0.834      0.665\n","    Transparent Closet        891          5      0.559        0.4      0.578      0.501\n","            Wall Panel        891         11      0.759      0.364      0.502      0.268\n","                Window        891        126      0.796      0.527      0.621      0.438\n","          Wooden floor        891         19      0.214      0.316      0.196      0.114\n","Speed: 0.2ms preprocess, 3.5ms inference, 0.0ms loss, 2.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n"]}],"source":["#익스트림 학습\n","results_x = model_x.train(data='/content/drive/MyDrive/Colab Notebooks/BigP/dataset/data.yaml', epochs=50, imgsz=416, patience=10, resume=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G2gglQkIOcXw"},"outputs":[],"source":["#디렉토리 내 모든 파일 이동\n","import os\n","import shutil\n","\n","source_folder = '/content/runs/detect/train/weights'\n","destination_folder = '/content/drive/MyDrive/Colab Notebooks/BigP/weights/x_e100'\n","\n","# 대상 폴더가 없으면 생성\n","if not os.path.exists(destination_folder):\n","    os.makedirs(destination_folder)\n","\n","for filename in os.listdir(source_folder):\n","    source_path = os.path.join(source_folder, filename)\n","    destination_path = os.path.join(destination_folder, filename)\n","    # 파일 이동\n","    shutil.move(source_path, destination_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2217,"status":"ok","timestamp":1703122119054,"user":{"displayName":"황교석","userId":"14795364109477648394"},"user_tz":-540},"id":"s3INkaOP-mg0","outputId":"2f84dd81-68f0-44ae-bd7c-c76cae5c0d0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","image 1/1 /content/모던1.png: 576x640 (no detections), 180.6ms\n","Speed: 8.1ms preprocess, 180.6ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","\n","image 1/1 /content/모던2.png: 416x640 (no detections), 228.5ms\n","Speed: 2.7ms preprocess, 228.5ms inference, 2.5ms postprocess per image at shape (1, 3, 416, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","\n","image 1/1 /content/모던3.png: 384x640 (no detections), 214.2ms\n","Speed: 2.6ms preprocess, 214.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","\n","image 1/1 /content/모던4.png: 416x640 (no detections), 19.1ms\n","Speed: 2.8ms preprocess, 19.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","\n","image 1/1 /content/모던5.png: 512x640 (no detections), 218.2ms\n","Speed: 3.1ms preprocess, 218.2ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","\n","image 1/1 /content/모던6.png: 448x640 (no detections), 220.0ms\n","Speed: 2.7ms preprocess, 220.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"]}],"source":["#예측\n","fn = ['1','2','3','4','5','6']\n","for n in fn:\n","    model_x.predict(f\"/content/모던{n}.png\", save=True, imgsz=640, conf=0.1)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(path):\n",
    "    with Image.open(path) as img:\n",
    "        return img.size  # (width, height)\n",
    "    \n",
    "def localize_objects_path(path): \n",
    "    objectBox = []\n",
    "    box = []\n",
    "    temp = []\n",
    "    imgWidth, imgHeight = get_image_size(path)\n",
    "    \n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "    # print(type(content))\n",
    "    # print(content)\n",
    "    objects = client.object_localization(image=image).localized_object_annotations\n",
    "\n",
    "    # print(f\"Number of objects found: {len(objects)}\")\n",
    "    for object_ in objects:\n",
    "        # print(f\"\\n{object_.name} (confidence: {object_.score})\")\n",
    "        # print(\"Normalized bounding polygon vertices: \")\n",
    "        for vertex in object_.bounding_poly.normalized_vertices:\n",
    "            # print(f\" - ({vertex.x}, {vertex.y})\")\n",
    "            pixel_x = int(vertex.x * imgWidth)\n",
    "            pixel_y = int(vertex.y * imgHeight)\n",
    "            # print(f\" - ({pixel_x}, {pixel_y})\")\n",
    "            temp.append(pixel_x)\n",
    "            temp.append(pixel_y)\n",
    "        box.append(temp[0])\n",
    "        box.append(temp[1])\n",
    "        box.append(temp[4])\n",
    "        box.append(temp[5])\n",
    "        temp = []\n",
    "        # print(box)\n",
    "        object_info = {\n",
    "            \"name\": object_.name,\n",
    "            \"confidence\": object_.score,\n",
    "            \"box\": box,\n",
    "        }\n",
    "        box = []\n",
    "        objectBox.append(object_info)\n",
    "        \n",
    "    return objectBox\n",
    "\n",
    "def obj_detection_path(path):\n",
    "    objects = localize_objects_path(path)\n",
    "\n",
    "    fileName = os.path.basename(path)\n",
    "    with Image.open(path) as img:\n",
    "        width, height = img.size\n",
    "        result = {\n",
    "            'fileName': fileName,\n",
    "            'size': [width, height],\n",
    "        }\n",
    "\n",
    "        for i, obj in enumerate(objects):\n",
    "            x1, y1, x2, y2 = obj['box']\n",
    "            cropped_img = img.crop((x1, y1, x2, y2))\n",
    "            obj['crop_img'] = cropped_img\n",
    "\n",
    "    result['objects'] = objects\n",
    "    return result\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from google.cloud import vision  \n",
    "\n",
    "path = 'C:/Users/user/Desktop/새 폴더/Detection/test_imge/AAIRLLENSleekandSturdyInchComputerDeskPerfectforWorkandStudyMultiPurposeTableforWritingDiningandWorkstation.jpg'\n",
    "\n",
    "ass = obj_detection_path(path)\n",
    "for obj in ass['objects']:\n",
    "    cimg = obj['crop_img']\n",
    "    cimg.show()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
